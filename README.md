# chatbot_ollama
An intelligent, conversational chatbot built using **LangChain**, **Streamlit**, and **FAISS**, powered by **Ollama** â€” a local LLM runtime for open-source models. 

This project demonstrates how to combine retrieval-augmented generation (RAG) and custom prompt workflows to build a fully local, privacy-friendly AI assistant.

---

## ğŸš€ Features

- ğŸ’¬ **Conversational Chatbot** â€” Natural, context-aware responses from open-source LLMs.  
- ğŸ§© **Retrieval-Augmented Generation (RAG)** â€” Enhances LLM performance using FAISS-based vector search over local knowledge bases.  
- âš¡ **LangChain Integration** â€” Modular prompt templates, chaining, and retrieval pipeline.  
- ğŸŒ **Streamlit Frontend** â€” Simple and interactive web UI for chatting and visualizing responses.  
- ğŸ›¡ï¸ **Local Inference** â€” Runs entirely on your system with Ollama; no external API keys required.  
- ğŸ” **Embeddings Support** â€” Custom document embeddings for knowledge-based question answering.  

---

## ğŸ—ï¸ Tech Stack

- **Programming Language:** Python 3.11+  
- **Frameworks & Libraries:**  
  - [LangChain](https://www.langchain.com/) â€“ chaining and RAG pipeline  
  - [Streamlit](https://streamlit.io/) â€“ UI interface  
  - [FAISS](https://faiss.ai/) â€“ vector similarity search  
  - [Ollama](https://ollama.ai/) â€“ open-source LLM runtime  
  - [SentenceTransformers](https://www.sbert.net/) â€“ embedding generation  

---

